<img src="https://www.austral.edu.ar/wp-content/uploads/2022/10/facultades-horizontales-03.png" width="50%" alt="Universidad Austral - Facultad de Ingenier√≠a">

# Navegaci√≥n Aut√≥noma de Drones Urbanos con Visi√≥n Monocular y Small Language Model (SLM)
### Tesis para Magister en Ciencia de Datos | Maestr√≠a en Ciencia de Datos 2024/2025

Directores:

-   [DEL ROSSO, Rodrigo](https://www.linkedin.com/in/rodrigodelrosso/)
-   [NUSKE, Ezequiel](https://www.linkedin.com/in/ezequiel-nuske-15137862/)

Alumno:

-   [NICOLAU, Jorge Enrique](https://www.linkedin.com/in/jorgenicolau/)

Este repositorio contiene la implementaci√≥n del Trabajo Final de M√°ster en Ingenier√≠a (Ciencia de Datos) de la **Universidad Austral**.

**T√≠tulo:** Navegaci√≥n Aut√≥noma de Drones Urbanos con Visi√≥n Monocular y SLM
**Autor:** Jorge Enrique Nicolau
**Director:** Rodrigo Del Rosso | **Codirector:** Ezequiel Omar Nuske

#### Proyecto:

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Activity](https://img.shields.io/badge/Log-2026--0115-teal)](LOG.md) 
[![Plan](https://img.shields.io/badge/Plan-Aprobado_2025--0829-drakgray)](./plan_tesis/nicolau-plan-aprobado.pdf)

#### Plataforma:

[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![UnrealEngine](https://img.shields.io/badge/Simulator-Unreal_Engine_5.5-green)](https://dev.epicgames.com/documentation/en-us/unreal-engine/unreal-engine-5-5-documentation?application_version=5.5)
[![AirSim](https://img.shields.io/badge/Plug_in-Cosys_AirSim-critical)](https://github.com/Cosys-Lab/Cosys-AirSim/)

---

## üìã Resumen del Proyecto

La navegaci√≥n aut√≥noma de drones en entornos urbanos densos, como la ciudad de Buenos Aires, presenta desaf√≠os cr√≠ticos debido a la p√©rdida de se√±al GPS, obst√°culos din√°micos y regulaciones estrictas. Este proyecto desarrolla un pipeline integral para la navegaci√≥n aut√≥noma de cuadric√≥pteros eVTOL utilizando **visi√≥n monocular** y **hardware de bajo costo**.

El sistema integra:
* **Modelos de Lenguaje Ligero (SLM)** para la toma de decisiones reactiva.
* **Visi√≥n por Computadora** (YOLOv8n, ORB-SLAM2) para percepci√≥n.
* **Simulaci√≥n Realista** en AirSim con entornos urbanos.

El objetivo principal es comparar el rendimiento de los SLM frente a las tradicionales M√°quinas de Estados Finitos (FSM) en tareas de detecci√≥n, mapeo y aterrizaje.

## üèóÔ∏è Arquitectura del Sistema

El proyecto se divide en dos pipelines principales de procesamiento:

### 1. Pipeline de Digitalizaci√≥n de Entornos (Digital Twin)
Generaci√≥n de escenarios 3D fotorrealistas de Buenos Aires para la simulaci√≥n.
1.  **Adquisici√≥n:** Extracci√≥n de frames de videos p√∫blicos (YouTube) de drones en la ciudad.
2.  **Preprocesamiento:** Filtrado y selecci√≥n de diversidad visual.
3.  **Modelado 3D:** Reconstrucci√≥n mediante **RealityCapture** y optimizaci√≥n de malla en **Blender**.
4.  **Despliegue:** Integraci√≥n de los modelos en **Unreal Engine / AirSim**.

### 2. Pipeline de Navegaci√≥n Aut√≥noma (SITL)
Ejecuci√≥n de la l√≥gica de vuelo y percepci√≥n.
* **Simulador:** AirSim provee datos sensoriales (C√°mara RGB, IMU, GPS).
* **Companion Computer Simulada:** Contenedor **Docker** emulando una **NVIDIA Jetson Nano** (L4T).
* **Stack de Percepci√≥n:**
    * *Detecci√≥n:* YOLOv8n (Obst√°culos).
    * *Segmentaci√≥n:* MobileNetV3 + U-Net (Zonas de aterrizaje).
    * *SLAM:* ORB-SLAM2 (Localizaci√≥n y Mapeo).
* **Control:** Interacci√≥n v√≠a **MAVLink** con un controlador de vuelo **PX4** virtual.

## üõ†Ô∏è Stack Tecnol√≥gico

* **Lenguaje:** Python, C++.
* **Simulaci√≥n:** Microsoft AirSim, Unreal Engine 5.5.
* **Visi√≥n por Computadora:** OpenCV, YOLOv8, ORB-SLAM2.
* **Deep Learning:** PyTorch / TensorFlow (para SLM y segmentaci√≥n).
* **Infraestructura:** Docker, NVIDIA TensorRT (para optimizaci√≥n en Jetson).
* **Protocolos:** MAVLink, ROS (Robot Operating System).

## üöÄ Instalaci√≥n y Uso

### Prerrequisitos
* NVIDIA GPU con soporte para CUDA (para correr Unreal Engine y entrenamiento).
* Docker Desktop instalado.
* Unreal Engine (versi√≥n compatible con AirSim).

### Configuraci√≥n del Entorno

1. **Clonar el repositorio:**
```bash
   git clone https://github.com/georgsmeinung/lm-drone.git
   cd lm-drone
```

2. **Iniciar la Simulaci√≥n (AirSim):**
* Descargar el proyecto `CityParkSim` con el plugin de AirSom compilado. El proyecto es muy pesado para subir a GitHub por lo que est√° en [Google Drive](https://drive.google.com/drive/folders/1ImTngQAt0gAlrXNOfOYs5csRWQt3IhS_?usp=sharing).
* Lanzar el entorno de virtual desde Unreal Engine editor en modo play.

3. **Probar conexi√≥n al Drone mediante:**
* Scripts de navegaci√≥n aut√≥noma `./python_poc/my_hello_drone.py` 

## üìä Evaluaci√≥n y M√©tricas

El sistema se eval√∫a comparativamente (SLM vs FSM) utilizando las siguientes m√©tricas:

* **Tasa de √âxito de Misi√≥n:** Porcentaje de recorridos completados sin colisiones.
* **Tiempo de Reacci√≥n:** Latencia entre percepci√≥n y comando de control.
* **Consumo Computacional:** Uso de CPU/GPU y memoria (FPS), crucial para validar la viabilidad en Jetson Nano.

## ü§ù Cr√©ditos

Este trabajo ha sido desarrollado como parte de la Maestr√≠a en Ciencia de Datos de la Universidad Austral.

* **Investigaci√≥n y Desarrollo:** Jorge Enrique Nicolau
* **Supervisi√≥n:** Rodrigo Del Rosso & Ezequiel Omar Nuske

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE.md](LICENSE.md) para m√°s detalles.
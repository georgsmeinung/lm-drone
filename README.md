<img src="https://www.austral.edu.ar/wp-content/uploads/2022/10/facultades-horizontales-03.png" width="50%" alt="Universidad Austral - Facultad de Ingenier√≠a">

# Maestr√≠a en Ciencia de Datos 2024/2025
# Tesis para Magister en Ciencia de Datos
# Navegaci√≥n Aut√≥noma de Drones Urbanos con Visi√≥n Monocular y SLM

Directores:

-   DEL ROSSO, Rodrigo
-   NUSKE, Ezequiel

Alumno:

-   NICOLAU, Jorge Enrique

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![AirSim](https://img.shields.io/badge/Simulator-AirSim-critical)](https://microsoft.github.io/AirSim/)
[![Platform](https://img.shields.io/badge/Hardware-Jetson%20Nano-green)](https://developer.nvidia.com/embedded/jetson-nano-developer-kit)

Este repositorio contiene la implementaci√≥n del Trabajo Final de M√°ster en Ingenier√≠a (Ciencia de Datos) de la **Universidad Austral**.

**T√≠tulo:** Navegaci√≥n Aut√≥noma de Drones Urbanos con Visi√≥n Monocular y SLM
**Autor:** Jorge Enrique Nicolau
**Director:** Rodrigo Del Rosso | **Codirector:** Ezequiel Omar Nuske

---

[BIT√ÅCORA](LOG.md)
[Plan de Tesis aprobado por el Consejo Acad√©mico](./plan_tesis/nicolau-plan-aprobado.pdf)

## üìã Resumen del Proyecto

La navegaci√≥n aut√≥noma de drones en entornos urbanos densos, como la ciudad de Buenos Aires, presenta desaf√≠os cr√≠ticos debido a la p√©rdida de se√±al GPS, obst√°culos din√°micos y regulaciones estrictas. Este proyecto desarrolla un pipeline integral para la navegaci√≥n aut√≥noma de cuadric√≥pteros eVTOL utilizando **visi√≥n monocular** y **hardware de bajo costo**.

El sistema integra:
* **Modelos de Lenguaje Ligero (SLM)** para la toma de decisiones reactiva.
* **Visi√≥n por Computadora** (YOLOv8n, ORB-SLAM2) para percepci√≥n.
* **Simulaci√≥n de Alta Fidelidad** en AirSim con entornos generados a partir de datos reales de la ciudad.

El objetivo principal es comparar el rendimiento de los SLM frente a las tradicionales M√°quinas de Estados Finitos (FSM) en tareas de detecci√≥n, mapeo y aterrizaje.

## üèóÔ∏è Arquitectura del Sistema

El proyecto se divide en dos pipelines principales de procesamiento:

### 1. Pipeline de Digitalizaci√≥n de Entornos (Digital Twin)
Generaci√≥n de escenarios 3D fotorrealistas de Buenos Aires para la simulaci√≥n.
1.  **Adquisici√≥n:** Extracci√≥n de frames de videos p√∫blicos (YouTube) de drones en la ciudad.
2.  **Preprocesamiento:** Filtrado y selecci√≥n de diversidad visual.
3.  **Modelado 3D:** Reconstrucci√≥n mediante **RealityCapture** y optimizaci√≥n de malla en **Blender**.
4.  **Despliegue:** Integraci√≥n de los modelos en **Unreal Engine / AirSim**.

### 2. Pipeline de Navegaci√≥n Aut√≥noma (SITL)
Ejecuci√≥n de la l√≥gica de vuelo y percepci√≥n.
* **Simulador:** AirSim provee datos sensoriales (C√°mara RGB, IMU, GPS).
* **Companion Computer Simulada:** Contenedor **Docker** emulando una **NVIDIA Jetson Nano** (L4T).
* **Stack de Percepci√≥n:**
    * *Detecci√≥n:* YOLOv8n (Obst√°culos).
    * *Segmentaci√≥n:* MobileNetV3 + U-Net (Zonas de aterrizaje).
    * *SLAM:* ORB-SLAM2 (Localizaci√≥n y Mapeo).
* **Control:** Interacci√≥n v√≠a **MAVLink** con un controlador de vuelo **PX4** virtual.

## üõ†Ô∏è Stack Tecnol√≥gico

* **Lenguaje:** Python, C++.
* **Simulaci√≥n:** Microsoft AirSim, Unreal Engine 4/5.
* **Visi√≥n por Computadora:** OpenCV, YOLOv8, ORB-SLAM2.
* **Deep Learning:** PyTorch / TensorFlow (para SLM y segmentaci√≥n).
* **Infraestructura:** Docker, NVIDIA TensorRT (para optimizaci√≥n en Jetson).
* **Protocolos:** MAVLink, ROS (Robot Operating System).

## üöÄ Instalaci√≥n y Uso

### Prerrequisitos
* NVIDIA GPU con soporte para CUDA (para correr Unreal Engine y entrenamiento).
* Docker Desktop instalado.
* Unreal Engine (versi√≥n compatible con AirSim).

### Configuraci√≥n del Entorno

1. **Clonar el repositorio:**
```bash
   git clone [https://github.com/georgsmeinung/lm-drone.git](https://github.com/georgsmeinung/lm-drone.git)
   cd lm-drone
```

2. **Iniciar la Simulaci√≥n (AirSim):**
* Lanzar el entorno de Buenos Aires en Unreal Engine.

3. **Iniciar el Drone Server (MCP):**
* Lanzar el MCP Server para interactuar con AirSim.

## üìä Evaluaci√≥n y M√©tricas

El sistema se eval√∫a comparativamente (SLM vs FSM) utilizando las siguientes m√©tricas:

* **Tasa de √âxito de Misi√≥n:** Porcentaje de recorridos completados sin colisiones.
* **Tiempo de Reacci√≥n:** Latencia entre percepci√≥n y comando de control.
* **Consumo Computacional:** Uso de CPU/GPU y memoria (FPS), crucial para validar la viabilidad en Jetson Nano.

## ü§ù Cr√©ditos

Este trabajo ha sido desarrollado como parte de la Maestr√≠a en Ciencia de Datos de la Universidad Austral.

* **Investigaci√≥n y Desarrollo:** Jorge Enrique Nicolau
* **Supervisi√≥n:** Rodrigo Del Rosso & Ezequiel Omar Nuske

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE.md](LICENSE.md) para m√°s detalles.
# Objetivo de tesis 1 (Generacion de ambientes de simulacion)

**Objetivo general**
Diseñar e implementar un entorno de simulación reproducible basado en **Unreal Engine (+ AirSim)** para integrar un **autopiloto de dron off-the-shelf** (p. ej., PX4/ArduPilot en SITL) equipado únicamente con **una cámara monocular** (sin sensores adicionales como LiDAR, radar o sensores de proximidad) y **cuantificar** cómo parámetros sencillos de automatización afectan el desempeño y la seguridad en misiones típicas; derivar **métricas y criterios de optimalidad** que permitan comparar configuraciones y seleccionar compromisos Pareto-óptimos.

## Objetivos específicos

1. **Entorno y agente**: Levantar un escenario UE+AirSim con mapas y condiciones controladas (viento, luz, clutter), conectar SITL del autopiloto equipado únicamente con una cámara monocular y exponer telemetría y comandos por API (RPC/MAVLink).
2. **Tareas y parámetros**: Definir misiones representativas (ruta por waypoints, patrullaje, inspección perimetral o de infraestructura, seguimiento de trayectoria) y variar **parámetros simples**:

   * Ganancias básicas (PID de posición/altitud/yaw).
   * Velocidad crucero y altura.
   * Espaciamiento de waypoints y radio de aceptación.
   * Sensibilidad de evitación de obstáculos/margen de seguridad basada en visión monocular.
   * Frecuencia de control y filtros; **latencia** y **ruido** sensorial simulados (especialmente en el procesamiento de imagen).
3. **Instrumentación de métricas**: Registrar estados, entradas y eventos para calcular **KPIs** de desempeño, seguridad, eficiencia y suavidad.
4. **Diseño experimental y análisis**: Ejecutar un **DoE** (factorial/Latin Hypercube), con réplicas y semillas controladas; analizar con **ANOVA/regresión/superficies de respuesta** y **frentes de Pareto**.
5. **Criterio de optimalidad**: Proponer una **función de costo** agregada y/o selección Pareto para recomendar configuraciones según el objetivo operativo (rápido vs eficiente vs seguro).
6. **Reproducibilidad**: Publicar contenedores, scripts y dataset de trayectorias/telemetría; documentación para replicar resultados.

## Preguntas de investigación

* Cuales son las metricas de desempeño y seguridad que se pueden obtener de la simulación?

* Cual es el estado del arte en piloto automatico de drones con sensado únicamente por cámara monocular?

## Consideraciones específicas para drones con cámara monocular

* **Limitaciones de percepción**: Sin sensores de distancia directos (LiDAR, radar), la estimación de profundidad y detección de obstáculos depende completamente del procesamiento de imagen monocular.

* **Algoritmos de visión**: Implementar técnicas de estimación de profundidad monocular, detección de obstáculos basada en visión, y navegación visual-inercial (VIO).

* **Condiciones de iluminación**: Evaluar el desempeño bajo diferentes condiciones de iluminación (día/noche, sombras, contraste) que afectan la calidad de la imagen.

* **Robustez visual**: Analizar la degradación del desempeño con ruido de imagen, compresión, resolución reducida, y condiciones climáticas adversas.


## Métricas propuestas (con fórmulas)

* **Error de seguimiento (RMSE)** de posición:

  $$
  \mathrm{RMSE}_p=\sqrt{\frac{1}{T}\sum_{t=1}^{T}\lVert \mathbf{p}(t)-\mathbf{p}_{\text{ref}}(t)\rVert^2}
  $$

  (descomponer en lateral/longitudinal y **heading error** sobretodo basado en la inspeccion de infraestructura).

* **Tiempo en tolerancia**: proporción de tiempo con $\lVert \mathbf{p}-\mathbf{p}_{\text{ref}}\rVert < \varepsilon$.

* **Tiempo total de misión** y **longitud de ruta real / óptima** (distancia en metros y tiempo en segundos).

* **Consumo energético (proxy)**:

  $$
  E \approx \int (a\cdot |\text{throttle}(t)| + b\cdot \lVert \boldsymbol{\omega}_{m}(t)\rVert)\,dt
  $$

  (usar comandos/velocidades de motores como proxy si no hay modelo eléctrico).

* **Suavidad** (confort/agotamiento mecánico): **jerk integral** $\int \lVert \dddot{\mathbf{p}}(t)\rVert dt$.
* **Esfuerzo de control**: $\int \lVert \mathbf{u}(t)\rVert^2 dt$.
* **Seguridad**: nº de **colisiones**, **near-miss** (< d\_min), **violaciones de altura** (detectadas por visión monocular).
* **Estabilidad transitoria**: **overshoot** y **tiempo de establecimiento** frente a escalones (altitud/velocidad).
* **Robustez**: tasa de éxito bajo **ruido** $\sim N(0, \sigma^2)$ y **latencia L** (barridos de $\sigma, L$).

* **Métricas específicas de visión**:
  * **Precisión de estimación de profundidad**: error RMSE entre profundidad estimada y ground truth.
  * **Tasa de detección de obstáculos**: precisión y recall en detección de obstáculos por visión.
  * **Calidad de tracking visual**: estabilidad del tracking de features y landmarks.
  * **Tiempo de procesamiento de imagen**: latencia en el pipeline de visión por frame.

## Parámetros a explorar (ejemplos concretos)

* **Control**: $K_p, K_i, K_d$ (posición/altitud/yaw); limitadores y anti-windup.
* **Misión**: velocidad objetivo, altura, radio de waypoint, densidad de waypoints.
* **Percepción/evitación**: umbral de distancia basado en visión, ganancia de repulsión, look-ahead, parámetros de procesamiento de imagen.
* **Cámara y visión**: resolución de imagen, frame rate, campo de visión (FOV), parámetros de calibración, algoritmos de estimación de profundidad.
* **Runtime**: tasa de loop (Hz), **latencia** inyectada, **ruido** en IMU/GPS/cámara, parámetros de procesamiento de imagen (resolución, frame rate, compresión).

## Criterio de optimalidad (Definir en base a resultados de la simulacion)

* **Función de costo** (para escenarios con una sola recomendación):

  $$
  J = w_1 \,\mathrm{RMSE}_p + w_2\, T_{\text{mis}} + w_3\, E + w_4\, \mathbb{I}_{\text{colisión}}\cdot \lambda + w_5\, \text{jerk\_int}
  $$

  con $\lambda \gg 0$ (penalización alta a colisión).

* **Selección multicriterio**: construir **frentes de Pareto** (p. ej., minimizar $\{\mathrm{RMSE}_p, E, T_{\text{mis}}, \text{colisiones}\}$).

## Metodología (resumen operativo)

1. **Setup**: Docker Compose (UE/AirSim, SITL, logger). Seeds fijas; versión fija del mapa.
2. **DoE**: factorial fraccional o LHS sobre 5–8 parámetros; $\geq$ 10 réplicas por punto.
3. **Ejecución**: orquestación por scripts; logging en Parquet/CSV + rosbag (si aplica).
4. **Análisis**: ANOVA/GLM, **Response Surface**, **Sobol** (si se quiere sensibilidad), y **Pareto**.
5. **Validación**: prueba cruzada entre mapas/viento; sanity check con un flight-log real (tenemos alguno?).

## Alcance y entregables

* **Entorno UE+AirSim** integrado con autopiloto OTS (PX4/ArduPilot SITL) equipado únicamente con cámara monocular.
* **Catálogo de misiones** reproducibles y **harness de experimentos**.
* **Dataset** y **reporte** con análisis, frentes de Pareto y guía de tunning básico.

## Definiciones matematicas

### Jerk integral

* Sea $\mathbf{p}(t) = [x(t), y(t), z(t)]$ la posición del dron.
* La **velocidad** es $\mathbf{v}(t) = \dot{\mathbf{p}}(t)$.
* La **aceleración** es $\mathbf{a}(t) = \ddot{\mathbf{p}}(t)$.
* El **jerk** es la **derivada temporal de la aceleración**:

  $$
  \mathbf{j}(t) = \dddot{\mathbf{p}}(t) = \frac{d \mathbf{a}(t)}{dt}
  $$

La métrica de suavidad se define como el **integral (o suma discreta) de la magnitud del jerk** durante toda la misión:

$$
J = \int_{0}^{T} \lVert \mathbf{j}(t) \rVert \, dt
$$

o, en forma discreta (con datos muestreados en pasos $\Delta t$):

$$
J \approx \sum_{k=1}^{N} \lVert \mathbf{j}_k \rVert \cdot \Delta t
$$

### Tiempo en tolerancia
La métrica se define como la **fracción de tiempo dentro de tolerancia** respecto al tiempo total de la misión $T$:

$$
\text{Tiempo en tolerancia} = \frac{1}{T} \int_{0}^{T} \mathbf{I}\!\left( \lVert \mathbf{p}(t) - \mathbf{p}_{ref}(t) \rVert < \varepsilon \right)\, dt
$$

donde $\mathbf{I}(\cdot)$ es la función indicadora que vale 1 si la condición se cumple y 0 en caso contrario.

En versión discreta (con $N$ muestras a intervalos $\Delta t$):

$$
\text{Tiempo en tolerancia} \approx \frac{1}{N} \sum_{k=1}^{N} \mathbf{I}\!\left( \lVert \mathbf{p}_k - \mathbf{p}_{ref,k} \rVert < \varepsilon \right)
$$

### Esfuerzo de control

Sea:

* $\mathbf{u}(t)$ = vector de entradas de control en el tiempo $t$.
  Ejemplo: comandos de motor $[u_1(t), u_2(t), u_3(t), u_4(t)]$ en un cuadricóptero.

La métrica se define como:

$$
C = \int_{0}^{T} \lVert \mathbf{u}(t) \rVert^2 \, dt
$$

donde:

$$
\lVert \mathbf{u}(t) \rVert^2 = \sum_{i=1}^{m} u_i(t)^2
$$

con $m$ el número de actuadores (motores, servos, etc.).

Si la señal se registra en $N$ instantes con paso $\Delta t$:

$$
C \approx \sum_{k=1}^{N} \lVert \mathbf{u}_k \rVert^2 \cdot \Delta t
$$

### Consumo energetico

Como en un simulador (AirSim/Unreal) no siempre se dispone de un modelo físico detallado de motores, batería y aerodinámica, se puede usar una **aproximación proxy** del consumo energético a partir de las señales de control.

Se define:

$$
E \;\approx\; \int_{0}^{T} \Big( a \cdot |\,\text{throttle}(t)\,| \;+\; b \cdot \lVert \boldsymbol{\omega}_m(t) \rVert \Big)\, dt
$$

donde:

* $\text{throttle}(t)$: comando de acelerador global (0–1).
* $\boldsymbol{\omega}_m(t) = [\omega_1(t), \omega_2(t), \dots, \omega_m(t)]$: velocidades angulares de los motores.
* $a, b$: constantes de calibración o pesos, que representan cómo cada término contribuye al consumo (se ajustan empíricamente).
* $T$: duración de la misión.

Con $N$ pasos de simulación y paso temporal $\Delta t$:

$$
E \;\approx\; \sum_{k=1}^{N} \Big( a \cdot |\,\text{throttle}_k\,| \;+\; b \cdot \lVert \boldsymbol{\omega}_{m,k} \rVert \Big)\, \Delta t
$$